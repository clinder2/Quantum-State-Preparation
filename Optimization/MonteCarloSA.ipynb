{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Simulated Annealing optimization using Monte Carlo methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "from random import randint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['interactive'] == True\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from qiskit_aer.aerprovider import AerSimulator\n",
    "from qiskit_aer import Aer, aerprovider\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.circuit.library import HGate, ZGate\n",
    "from qiskit.circuit import ClassicalRegister, QuantumRegister\n",
    "from qiskit.primitives import StatevectorEstimator as Estimator\n",
    "from qiskit.primitives import StatevectorSampler as Sampler\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit.quantum_info import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reversely find a parameter.\n",
    "\n",
    "Input y is desired prepared quantum state. (L2 Normalized |y|^2 = 1)\n",
    "Input optimization_method is function used to optimize the parameters.\n",
    "Find parameters of variational quantum circuit \"RealAmplitude\" that can prepare y.\n",
    "'''\n",
    "def find_parameter(y, optimization_method: callable):\n",
    "    n = int(math.log2(len(y))) \n",
    "    ansatz = RealAmplitudes(n, reps=1) \n",
    "    parameters = np.ones(ansatz.num_parameters)  \n",
    "    simulator = AerSimulator(method='statevector') \n",
    "    meas = ClassicalRegister(1, \"meas\") \n",
    "    qreg = QuantumRegister(2 * n + 1) \n",
    "    c = QuantumCircuit(qreg, meas) \n",
    "\n",
    "    # Prepare the circuit for the swap test\n",
    "    a = [1]\n",
    "    b = [n + 1]\n",
    "    for i in range(2, n + 1):\n",
    "        a.append(i)\n",
    "        b.append(n + i)\n",
    "\n",
    "    final = c.compose(ansatz, a) \n",
    "    final.initialize(y, b) \n",
    "    final.save_statevector(label=\"ans\") \n",
    "    final.h(0) \n",
    "\n",
    "    # Perform the swap test\n",
    "    for i in range(1, n + 1):\n",
    "        final.cswap(0, i, n + i) \n",
    "    final.h(0) \n",
    "    final.measure([0], meas) \n",
    "\n",
    "    # Transpile and run the circuit\n",
    "    circ = transpile(final, simulator) \n",
    "    circfinal = circ.assign_parameters(parameters) \n",
    "    results = simulator.run(circfinal).result() \n",
    "    init_counts = results.get_counts()\n",
    "    print(f\"Counts before optimization: {init_counts}\") \n",
    "    \n",
    "    # Visualize results of the original implementation\n",
    "    # visualize_results(init_counts, \"Before Optimization\")\n",
    "\n",
    "    # Optimization\n",
    "    Energy = E(parameters, circ, simulator) \n",
    "    anneal = optimization_method(100, parameters, circ, simulator) \n",
    "    print(f\"Energy: {Energy}\") \n",
    "\n",
    "    # Update circuit with optimized parameters and run again\n",
    "    circfinal = circ.assign_parameters(anneal)\n",
    "    results = simulator.run(circfinal).result()\n",
    "    optimized_counts = results.get_counts() \n",
    "    \n",
    "\n",
    "    # Calculate and print results\n",
    "    b = optimized_counts.get('1', 0) # Number of times qc measured '1'\n",
    "    s = (1 - (2 / 1024) * b) # Success value\n",
    "    # circfinal.draw(output=\"mpl\")\n",
    "    #matplotlib.pyplot.show() \n",
    "    print(f\"After optimization: {str(results.get_counts())}\") \n",
    "    print(f\"Success value: {s}\")\n",
    "\n",
    "    # Visualize results of the Monte Carlo optimization\n",
    "    # visualize_results(optimized_counts, \"After Optimization\")\n",
    "\n",
    "    # Calculate and print partial traces\n",
    "    temp = partial_trace(results.data(0)['ans'], [0, 3, 4])\n",
    "    partial = np.diagonal(temp)\n",
    "    temp = partial_trace(results.data(0)['ans'], [0, 1, 2])\n",
    "    partial2 = np.diagonal(temp)\n",
    "    norm = np.linalg.norm(partial - partial2) \n",
    "    print(\"Norm of the difference between partial traces:\", norm)\n",
    "\n",
    "    return parameters \n",
    "\n",
    "# Function to calculate cost based on parameters\n",
    "def cost_func(params, ansatz, simulator):\n",
    "    circfinal = ansatz.assign_parameters(params) \n",
    "    results = simulator.run(circfinal, shots=1024).result() \n",
    "    counts = results.get_counts() \n",
    "    b = counts.get('1', 0) \n",
    "    s = -1 * (1 - ((2 / 1024) * b)) \n",
    "    return s \n",
    "\n",
    "# Function to calculate energy based on parameters\n",
    "def E(params, ansatz, simulator):\n",
    "    circfinal = ansatz.assign_parameters(params) \n",
    "    results = simulator.run(circfinal, shots=20).result() \n",
    "    temp = partial_trace(results.data(0)['ans'], [0, 3, 4])\n",
    "    partial = np.diagonal(temp) \n",
    "    temp = partial_trace(results.data(0)['ans'], [0, 1, 2])\n",
    "    partial2 = np.diagonal(temp) \n",
    "    norm = np.linalg.norm(partial - partial2) \n",
    "    return norm \n",
    "\n",
    "# Function to visualize the results of the quantum circuit\n",
    "def visualize_results(counts, title):\n",
    "    plt.bar(counts.keys(), counts.values())\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Measurement Outcome')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Optimization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Annealing optimization\n",
    "def simulated_annealing(runs, params, ansatz, simulator):\n",
    "    B = E(params, ansatz, simulator) \n",
    "    prev_E = B\n",
    "\n",
    "    # Temperature function for simulated annealing\n",
    "    def T(t):\n",
    "        c = 0.02\n",
    "        a = 0.01\n",
    "        temperature = c / (a + math.log(t)) \n",
    "        return temperature\n",
    "\n",
    "    # Main loop for simulated annealing\n",
    "    for t in range(1, runs):\n",
    "        delta = np.random.normal(0, .1, 4) \n",
    "        params_new = params + delta \n",
    "        E_new = E(params_new, ansatz, simulator) \n",
    "        delta_E = E_new - prev_E \n",
    "\n",
    "        if delta_E <= 0:\n",
    "            params = params_new\n",
    "            prev_E = E_new\n",
    "        else:\n",
    "            h = math.pow(math.e, -1 * delta_E / T(t)) \n",
    "            U = np.random.normal(.5, .5, 1) \n",
    "            if U < h:\n",
    "                params = params_new\n",
    "                prev_E = E_new\n",
    "\n",
    "    return params \n",
    "\n",
    "# Global Best Particle Swarm optimization\n",
    "def gbest_pso(runs, params, ansatz, simulator):\n",
    "    num_particles = 40  # Number of particles in the swarm\n",
    "    dimensions = len(params)  # Number of parameters to optimize\n",
    "\n",
    "    particles = np.random.rand(num_particles, dimensions) * 2 - 1  # Random positions in range [-1, 1]\n",
    "    velocities = np.random.rand(num_particles, dimensions) * 0.1  # Small random velocities\n",
    "    personal_best_positions = np.copy(particles)  # Initial best positions for each particle\n",
    "    personal_best_scores = [cost_func(p, ansatz, simulator) for p in particles]  # Initial best scores for each particle\n",
    "\n",
    "    global_best_position = personal_best_positions[np.argmin(personal_best_scores)]  # Best position from all particles\n",
    "\n",
    "    for _ in range(runs):\n",
    "        # Update personal best and global best\n",
    "        for i in range(num_particles):\n",
    "            score = cost_func(particles[i], ansatz, simulator)  # New score\n",
    "\n",
    "            # Update personal best\n",
    "            if score < personal_best_scores[i]:\n",
    "                personal_best_scores[i] = score\n",
    "                personal_best_positions[i] = particles[i]\n",
    "\n",
    "            # Update global best\n",
    "            if score < cost_func(global_best_position, ansatz, simulator):\n",
    "                global_best_position = particles[i]\n",
    "\n",
    "        # Update velocities and positions\n",
    "        for i in range(num_particles - 1):\n",
    "            c1 = 0.4  # Personal best weight\n",
    "            c2 = 0.4  # Global best weight\n",
    "            r1 = np.random.rand(dimensions)\n",
    "            r2 = np.random.rand(dimensions)\n",
    "\n",
    "            # Update velocity\n",
    "            velocities[i+1] = (velocities[i] + \n",
    "                            c1 * r1 * (personal_best_positions[i] - particles[i]) + \n",
    "                            c2 * r2 * (global_best_position - particles[i]))\n",
    "\n",
    "            # Update position\n",
    "            particles[i+1] = particles[i] + velocities[i+1]\n",
    "\n",
    "    return global_best_position\n",
    "\n",
    "# Differential Evolution optimization\n",
    "def diff_evolution(runs, params, ansatz, simulator):\n",
    "    bounds = [(-1, 1)] * len(params)\n",
    "    dimensions = len(bounds)\n",
    "    popsize = 20\n",
    "    mut = 0.8  # Mutation factor, usually chosen from the interval [0.5, 2.0]\n",
    "    crossp = 0.7  # Crossover probability, between [0, 1]\n",
    "\n",
    "    # Initialization\n",
    "    pop = np.random.rand(popsize, dimensions)\n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    diff = np.fabs(min_b - max_b)\n",
    "    pop_denorm = min_b + pop * diff\n",
    "    fitness = np.asarray([cost_func(ind, ansatz, simulator) for ind in pop_denorm])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = pop_denorm[best_idx]\n",
    "\n",
    "    for i in range(runs):\n",
    "        for j in range(popsize):\n",
    "            # Mutation\n",
    "            idxs = [idx for idx in range(popsize) if idx != j]\n",
    "            a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n",
    "            mutant = np.clip(a + mut * (b - c), 0, 1)\n",
    "\n",
    "            # Recombination\n",
    "            cross_points = np.random.rand(dimensions) < crossp\n",
    "            if not np.any(cross_points):\n",
    "                cross_points[np.random.randint(0, dimensions)] = True\n",
    "            trial = np.where(cross_points, mutant, pop[j])\n",
    "\n",
    "            # Replacement\n",
    "            trial_denorm = min_b + trial * diff\n",
    "            f = cost_func(trial_denorm, ansatz, simulator)\n",
    "            if f < fitness[j]:\n",
    "                fitness[j] = f\n",
    "                pop[j] = trial\n",
    "                if f < fitness[best_idx]:\n",
    "                    best_idx = j\n",
    "                    best = trial_denorm\n",
    "\n",
    "    return best\n",
    "\n",
    "# Stochastic Hill Climbing optimization\n",
    "def stochastic_hill_climbing(runs, params, ansatz, simulator):\n",
    "    # To implement\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random vector: [0.4101754  0.03815585 0.66772739 0.62003258]\n",
      "\n",
      "Counts before optimization: {'1': 75, '0': 949}\n",
      "Energy: 0.3500692177742775\n",
      "After optimization: {'1': 6, '0': 1018}\n",
      "Success value: 0.98828125\n",
      "Norm of the difference between partial traces: 0.0846643113681168\n",
      "Simulated Annealing Time: 0.0897 seconds\n",
      "\n",
      "Counts before optimization: {'1': 46, '0': 978}\n",
      "Energy: 0.3500692177742775\n",
      "After optimization: {'1': 230, '0': 794}\n",
      "Success value: 0.55078125\n",
      "Norm of the difference between partial traces: 0.5675783830771788\n",
      "Particle Swarm Optimization Time: 19.2672 seconds\n",
      "\n",
      "Counts before optimization: {'1': 55, '0': 969}\n",
      "Energy: 0.3500692177742775\n",
      "After optimization: {'1': 5, '0': 1019}\n",
      "Success value: 0.990234375\n",
      "Norm of the difference between partial traces: 0.07685726992432212\n",
      "Differential Evolution Time: 5.0239 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution block\n",
    "randvect = [randint(0, 100) for p in range(0, 4)] \n",
    "norm = np.linalg.norm(randvect) \n",
    "randvect = randvect / norm \n",
    "print(f\"Random vector: {randvect}\\n\")\n",
    "\n",
    "# Timing for Simulated Annealing\n",
    "start_time = time.time()\n",
    "original_parameters_sa = find_parameter(randvect, simulated_annealing)\n",
    "sa_time = time.time() - start_time\n",
    "print(f\"Simulated Annealing Time: {sa_time:.4f} seconds\\n\")\n",
    "\n",
    "# Timing for Particle Swarm Optimization\n",
    "start_time = time.time()\n",
    "original_parameters_pso = find_parameter(randvect, gbest_pso)\n",
    "pso_time = time.time() - start_time\n",
    "print(f\"Particle Swarm Optimization Time: {pso_time:.4f} seconds\\n\")\n",
    "\n",
    "\n",
    "# Timing for Differential Evolution\n",
    "start_time = time.time()\n",
    "original_parameters_pso = find_parameter(randvect, diff_evolution)\n",
    "pso_time = time.time() - start_time\n",
    "print(f\"Differential Evolution Time: {pso_time:.4f} seconds\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum-State-Preparation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
